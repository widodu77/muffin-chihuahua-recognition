{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e_EV2eaXG4MP"
      },
      "outputs": [],
      "source": [
        "# Python packages\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HfkNZmEEG-gX"
      },
      "outputs": [],
      "source": [
        "class MLP1(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size=2):\n",
        "        super(MLP1, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "K1bT9ollGxq3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The predicted class is: Muffin\n"
          ]
        }
      ],
      "source": [
        "input_size, hidden_size, output_size = 64*64*3, 64*64*3, 2\n",
        "# Load the saved model\n",
        "model = MLP1(input_size, hidden_size, output_size) # model initialization\n",
        "model.load_state_dict(torch.load('./mlp_model.pth')) # take already prepared weights\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Define image transformations\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),  # Resize the image to match model input size\n",
        "    transforms.ToTensor()  # Convert PIL image to PyTorch tensor\n",
        "])\n",
        "\n",
        "# Load and preprocess the image\n",
        "image_path = './dataset/chihuahua/img_4_53.jpg'  # Specify the path to your image\n",
        "image_path = './muffintest.jpg'  # Specify the path to your image\n",
        "\n",
        "image = Image.open(image_path)\n",
        "image = image_transform(image)\n",
        "image = image.view(1, -1)  # Add batch dimension\n",
        "\n",
        "# Forward pass through the model to get predictions\n",
        "with torch.no_grad():\n",
        "    output = model(image)\n",
        "    probabilities = torch.softmax(output, dim=1)\n",
        "    predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "\n",
        "# Define class labels\n",
        "class_labels = ['Chihuahua', 'Muffin']\n",
        "\n",
        "# Print prediction\n",
        "print(f'The predicted class is: {class_labels[predicted_class]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
